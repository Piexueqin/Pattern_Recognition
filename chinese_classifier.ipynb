{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import pandas as pd\n",
    "df_technology = pd.read_csv(\"./data/technology_news.csv\", encoding='utf-8')\n",
    "df_technology = df_technology.dropna()\n",
    "\n",
    "df_car = pd.read_csv(\"./data/car_news.csv\", encoding='utf-8')\n",
    "df_car = df_car.dropna()\n",
    "\n",
    "df_entertainment = pd.read_csv(\"./data/entertainment_news.csv\", encoding='utf-8')\n",
    "df_entertainment = df_entertainment.dropna()\n",
    "\n",
    "df_military = pd.read_csv(\"./data/military_news.csv\", encoding='utf-8')\n",
    "df_military = df_military.dropna()\n",
    "\n",
    "df_sports = pd.read_csv(\"./data/sports_news.csv\", encoding='utf-8')\n",
    "df_sports = df_sports.dropna()\n",
    "\n",
    "technology = df_technology.content.values.tolist()[1000:21000]\n",
    "car = df_car.content.values.tolist()[1000:21000]\n",
    "entertainment = df_entertainment.content.values.tolist()[:20000]\n",
    "military = df_military.content.values.tolist()[:20000]\n",
    "sports = df_sports.content.values.tolist()[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=pd.read_csv(\"data/stopwords.txt\",index_col=False,quoting=3,sep=\"\\t\",names=['stopword'], encoding='utf-8')\n",
    "stopwords=stopwords['stopword'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 去停用词："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\vivi\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.321 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(content_lines, sentences, category):\n",
    "    for line in content_lines:\n",
    "        try:\n",
    "            segs=jieba.lcut(line)\n",
    "            segs = filter(lambda x:len(x)>1, segs)\n",
    "            segs = filter(lambda x:x not in stopwords, segs)\n",
    "            sentences.append((\" \".join(segs), category))\n",
    "        except Exception:\n",
    "            print(line)\n",
    "            continue \n",
    "\n",
    "#生成训练数据\n",
    "sentences = []\n",
    "\n",
    "preprocess_text(technology, sentences, 'technology')\n",
    "preprocess_text(car, sentences, 'car')\n",
    "preprocess_text(entertainment, sentences, 'entertainment')\n",
    "preprocess_text(military, sentences, 'military')\n",
    "preprocess_text(sports, sentences, 'sports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中国 学生 体质 健康 水平 下降 警示 忧虑 多年 不绝于耳 现状 改变 学校 体育 突破口 sports\n",
      "演练 部队 紧急 转移 炊事员 负重 过大 行动迟缓 暴露 目标 military\n",
      "聚焦 国际化 议题 主会场 海航 生态 科技 消费者 业务 总裁 左力 万达 酒店 管理 公司 酒店 管理 总部 市场 销售部 总经理 于洋 天海 邮轮 执行 总裁兼 首席 战略 官魏裕 企业 发展 经历 讨论 中国 旅游 企业 全球 布局 国际化 进程 旅游业 大势所趋 深感 认同 世界 中餐 联合会 行业 专家 高福 中餐 美食 走向世界 怀抱 信心 期望 国际 娱乐 景区 运营 企业 海外 旅游局 代表 交流 国际 企业 中国 市场 策略 变迁 technology\n",
      "摄影 指导 布拉德 鲁师 拍摄 作品 库克 美术 指导 克里斯蒂安 米雷兹 参与 喜剧 悬疑 歌舞 题材 凯撒 万岁 动作 奇幻 题材 古拉 元年 脍炙人口 电影 作品 entertainment\n",
      "古佳耶 大提琴 北方 游牧民族 音乐 还于 国家大剧院 新闻 发布厅 隆重举行 CD 专辑 发布会 观众 现场 欣赏 到娜 木拉 老师 携手 艺术家 演奏 小宝贝 木卡姆 狂想曲 白色 毡房 专辑 作品 极富 创造力 音乐 精湛 演奏 深厚 北方 少数民族 文化 水准 唱片 制作 听众 带来 美好 游牧民族 文化 体验 entertainment\n",
      "辽足 造血 功能强大 符合 U23 年龄段 球员 冯伯元 出场 sports\n",
      "央视 解说 愤慨 sports\n",
      "歌手 演出 该降 对此 有人 交给 市场 歌手 演出 商都 尊重 市场 涨价 赚钱 证明 涨得 道理 相关 人士 直言 歌手 降价 定价 不合理 虚荣 身价 价格 定得 太高 大部分 时间 待在家里 过气 歌手 二线 城市 没人 跑跑 三四 首歌 国外 唱够 小时 城市 肯定 市场 宗禾 entertainment\n",
      "CBA 不到 半年 国奥 男篮 一员 第二年 夺得 亚青赛 MVP 球队 夺冠 CBA 职业生涯 第二年 年龄段 球员 征战 星锐 赛时 全明星 正赛 球员 广厦 内线 外援 霍尔 实力 慢慢 下降 林志杰 慢慢 老去 之时 球队 攻防 两端 核心 亮点 sports\n",
      "中国互联网络信息中心 互联网 发展 研究部 主任 刘鑫 互联网 产业 影响 最先 服务业 外卖 网约车 工业 农业 未来 互联网 工业 影响 智能 制造 个性化 定制 显现出来 互联网 连接 用户 产品 工业 制造 产品 距离 用户 越近 互联网 工业 领域 影响 表现 生产 衣服 手机 电脑 用户 个性 定制 智能 制造 降低成本 改造 生产流程 technology\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences[:10]:\n",
    "    print(sentence[0], sentence[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x, y = zip(*sentences)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65696"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer(\n",
    "    analyzer='word', # tokenise by character ngrams\n",
    "    max_features=4000,  # keep the most common 1000 ngrams\n",
    ")\n",
    "vec.fit(x_train)\n",
    "\n",
    "def get_features(x):\n",
    "    vec.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(vec.transform(x_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8367505365541805"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(vec.transform(x_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21899"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer(\n",
    "    analyzer='word', # tokenise by character ngrams\n",
    "    ngram_range=(1,4),  # use ngrams of size 1 and 2\n",
    "    max_features=20000,  # keep the most common 1000 ngrams\n",
    ")\n",
    "vec.fit(x_train)\n",
    "\n",
    "def get_features(x):\n",
    "    vec.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.876067400337915"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(vec.transform(x_train), y_train)\n",
    "classifier.score(vec.transform(x_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "class TextClassifier():\n",
    "\n",
    "    def __init__(self, classifier=MultinomialNB()):\n",
    "        self.classifier = classifier\n",
    "        self.vectorizer = CountVectorizer(analyzer='word', ngram_range=(1,4), max_features=20000)\n",
    "\n",
    "    def features(self, X):\n",
    "        return self.vectorizer.transform(X)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.vectorizer.fit(X)\n",
    "        self.classifier.fit(self.features(X), y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.classifier.predict(self.features([x]))\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return self.classifier.score(self.features(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['military']\n",
      "0.876067400337915\n"
     ]
    }
   ],
   "source": [
    "text_classifier = TextClassifier()\n",
    "text_classifier.fit(x_train, y_train)\n",
    "print(text_classifier.predict('这 是 有史以来 最 大 的 一 次 军舰 演习'))\n",
    "print(text_classifier.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8475272843508836"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(vec.transform(x_train), y_train)\n",
    "svm.score(vec.transform(x_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "svm.fit(vec.transform(x_train), y_train)\n",
    "svm.score(vec.transform(x_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "class TextClassifier():\n",
    "\n",
    "    def __init__(self, classifier=SVC(kernel='linear')):\n",
    "        self.classifier = classifier\n",
    "        self.vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1,3), max_features=12000)\n",
    "\n",
    "    def features(self, X):\n",
    "        return self.vectorizer.transform(X)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.vectorizer.fit(X)\n",
    "        self.classifier.fit(self.features(X), y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.classifier.predict(self.features([x]))\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return self.classifier.score(self.features(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_classifier = TextClassifier()\n",
    "text_classifier.fit(x_train, y_train)\n",
    "print(text_classifier.predict('这 是 有史以来 最 大 的 一 次 军舰 演习'))\n",
    "print(text_classifier.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
